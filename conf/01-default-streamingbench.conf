#########################################################
# General Stream Config
#########################################################

# Note to ensure benchName to be consistent with datagen type. Numeric data for statistics and text data for others
# (available benchname: identity, repartition)  TDB: sample project grep wordcount distinctcount statistics
hibench.streambench.testCase	identity

# zookeeper address for Kakfa serverce, (default: HOSTNAME:HOSTPORT)
hibench.streambench.zkHost HOSTNAME:HOSTPORT

# Probability used in sample test case
hibench.streambench.sampleProbability 0.1

# Indicate whether in debug mode for correctness verfication (default: false)
hibench.streambench.debugMode false

# JARS
hibench.streambench.datagen.jar ${hibench.home}/src/streambench/datagen/target/datagen-0.2-jar-with-dependencies.jar
hibench.streambench.sparkbench.jar	${hibench.home}/src/streambench/sparkbench/target/streaming-bench-spark_0.1-5.0-SNAPSHOT-${hibench.spark.version}-jar-with-dependencies.jar
hibench.streambench.stormbench.jar	${hibench.home}/src/streambench/stormbench/target/streaming-bench-storm_0.1-5.0-SNAPSHOT.jar
hibench.streambench.gearpump.jar ${hibench.home}/src/streambench/gearpumpbench/target/streaming-bench-gearpump_0.1-5.0-SNAPSHOT-jar-with-dependencies.jar
hibench.streambench.flinkbench.jar ${hibench.home}/src/streambench/flinkbench/target/streaming-bench-flink-5.0-SNAPSHOT-jar-with-dependencies.jar

#########################################################
# Kafka Config
#########################################################

# Kafka home
hibench.streambench.kafka.home	/PATH/TO/KAFKA/HOME

# the topic that spark will receive input data (default: ${hibench.streambench.testCase})
hibench.streambench.kafka.topic	${hibench.streambench.testCase}

# number of partitions of generated topic (default 20)
hibench.streambench.kafka.topicPartitions	20

# consumer group of the consumer for kafka (default: HiBench)
hibench.streambench.kafka.consumerGroup	HiBench

# Kafka broker lists, written in mode "host:port,host:port,..." (default: HOSTNAME:HOSTPORT)
hibench.streambench.kafka.brokerList	HOSTNAME:HOSTPORT

# Set the starting offset of kafkaConsumer (default: largest)
hibench.streambench.kafka.offsetReset largest
#########################################################
# Data Generator Config
#########################################################

# Interval span in millisecond (default: 50)
hibench.streambench.datagen.intervalSpan 50

# Number of records to generate per interval span (default: 5)
hibench.streambench.datagen.recordsPerInterval  5

# Number of total records that will be generated (default: -1 means infinity)
hibench.streambench.datagen.totalRecords	-1

# Total round count of data send (default: -1 means infinity)
hibench.streambench.datagen.totalRounds -1

# default path to store seed files (default: ${hibench.hdfs.data.dir}/Streaming)
hibench.streambench.datagen.dir ${hibench.hdfs.data.dir}/Streaming

# fixed length of record (default: 200)
hibench.streambench.datagen.recordLength 200

# Number of KafkaProducer running on different thread (default: 1)
# The limitation of a single KafkaProducer is about 100Mb/s
hibench.streambench.datagen.producerNumber 1

#########################################################
# Spark Streaming Config
#########################################################

# Number of nodes that will receive kafka input (default: 4)
hibench.streambench.spark.receiverNumber	4

# Spark streaming Batchnterval in millisecond (default 100)
hibench.streambench.spark.batchInterval	100

# Indicate RDD storage level. (default: 2)
# 0 = StorageLevel.MEMORY_ONLY
# 1 = StorageLevel.MEMORY_AND_DISK_SER
# other = StorageLevel.MEMORY_AND_DISK_SER_2
hibench.streambench.spark.storageLevel 2

# indicate whether to test the write ahead log new feature (default: false)
hibench.streambench.spark.enableWAL false

# if testWAL is true, this path to store stream context in hdfs shall be specified. If false, it can be empty (default: /var/tmp)
hibench.streambench.spark.checkpointPath /var/tmp

# whether to use direct approach or not (dafault: true)
hibench.streambench.spark.useDirectMode	true

#########################################################
# Flink Config
#########################################################
hibench.streambench.flink.home	/PATH/TO/FLINK/HOME

# default parallelism of flink job
hibench.streambench.flink.parallelism 20

hibench.streambench.flink.bufferTimeout 5

#########################################################
# Storm Config
#########################################################

# STORM_BIN_HOME
hibench.streambench.storm.home	/PATH/TO/STORM/HOME

# nimbus of storm cluster
hibench.streambench.storm.nimbus		HOSTNAME_OF_STORM_NIMBUS
hibench.streambench.storm.nimbusAPIPort	6627

# time interval to contact nimbus to judge if finished
hibench.streambench.storm.nimbusContactInterval	10

# number of workers of Storm. Number of most bolt threads is also equal to this param.
hibench.streambench.storm.worker_count	12

# number of kafka spout threads of Storm
hibench.streambench.storm.spout_threads	12

# number of bolt threads altogether
hibench.streambench.storm.bolt_threads	12

# kafka arg indicating whether to read data from kafka from the start or go on to read from last position
hibench.streambench.storm.read_from_start	true

# whether to turn on ack
hibench.streambench.storm.ackon		true

#########################################################
# Gearpump Config
#########################################################

hibench.streambench.gearpump.home  /PATH/TO/GEARPUMP/HOME

hibench.streambench.gearpump.executors  1

hibench.streambench.gearpump.parallelism  1



